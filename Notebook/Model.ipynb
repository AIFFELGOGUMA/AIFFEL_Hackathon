{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d3c9916-e991-433a-b4f8-0244d73edfc8",
   "metadata": {},
   "source": [
    "# < Model >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af8ce07-43d9-4da9-bd79-a310b4074e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cea0e9d-51e7-4033-a0de-3745bf7d6d4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942a519f-cfd9-49ee-9ddc-29f1e5480118",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encoder using pre-trained ResNet18\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        modules = list(resnet.children())[:-2]\n",
    "        self.block1 = nn.Sequential(*modules[:3])\n",
    "        self.block2 = nn.Sequential(*modules[3:5])\n",
    "        self.block3 = nn.Sequential(*modules[5])\n",
    "        self.block4 = nn.Sequential(*modules[6])\n",
    "        self.block5 = nn.Sequential(*modules[7])\n",
    "\n",
    "    def forward(self, x):\n",
    "        f1 = self.block1(x)  # (64, 16, 64)\n",
    "        f2 = self.block2(f1)  # (64, 8, 32)\n",
    "        f3 = self.block3(f2)  # (128, 4, 16)\n",
    "        f4 = self.block4(f3)  # (256, 2, 8)\n",
    "        f5 = self.block5(f4)  # (512, 1, 4)\n",
    "        return f5, (f1, f2, f3, f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d8d349a-74f5-45a8-9464-aae23dd17348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Encoder                                  [32, 512, 1, 4]           --\n",
       "├─Sequential: 1-1                        [32, 64, 16, 64]          --\n",
       "│    └─Conv2d: 2-1                       [32, 64, 16, 64]          9,408\n",
       "│    └─BatchNorm2d: 2-2                  [32, 64, 16, 64]          128\n",
       "│    └─ReLU: 2-3                         [32, 64, 16, 64]          --\n",
       "├─Sequential: 1-2                        [32, 64, 8, 32]           --\n",
       "│    └─MaxPool2d: 2-4                    [32, 64, 8, 32]           --\n",
       "│    └─Sequential: 2-5                   [32, 64, 8, 32]           --\n",
       "│    │    └─BasicBlock: 3-1              [32, 64, 8, 32]           73,984\n",
       "│    │    └─BasicBlock: 3-2              [32, 64, 8, 32]           73,984\n",
       "├─Sequential: 1-3                        [32, 128, 4, 16]          --\n",
       "│    └─BasicBlock: 2-6                   [32, 128, 4, 16]          --\n",
       "│    │    └─Conv2d: 3-3                  [32, 128, 4, 16]          73,728\n",
       "│    │    └─BatchNorm2d: 3-4             [32, 128, 4, 16]          256\n",
       "│    │    └─ReLU: 3-5                    [32, 128, 4, 16]          --\n",
       "│    │    └─Conv2d: 3-6                  [32, 128, 4, 16]          147,456\n",
       "│    │    └─BatchNorm2d: 3-7             [32, 128, 4, 16]          256\n",
       "│    │    └─Sequential: 3-8              [32, 128, 4, 16]          8,448\n",
       "│    │    └─ReLU: 3-9                    [32, 128, 4, 16]          --\n",
       "│    └─BasicBlock: 2-7                   [32, 128, 4, 16]          --\n",
       "│    │    └─Conv2d: 3-10                 [32, 128, 4, 16]          147,456\n",
       "│    │    └─BatchNorm2d: 3-11            [32, 128, 4, 16]          256\n",
       "│    │    └─ReLU: 3-12                   [32, 128, 4, 16]          --\n",
       "│    │    └─Conv2d: 3-13                 [32, 128, 4, 16]          147,456\n",
       "│    │    └─BatchNorm2d: 3-14            [32, 128, 4, 16]          256\n",
       "│    │    └─ReLU: 3-15                   [32, 128, 4, 16]          --\n",
       "├─Sequential: 1-4                        [32, 256, 2, 8]           --\n",
       "│    └─BasicBlock: 2-8                   [32, 256, 2, 8]           --\n",
       "│    │    └─Conv2d: 3-16                 [32, 256, 2, 8]           294,912\n",
       "│    │    └─BatchNorm2d: 3-17            [32, 256, 2, 8]           512\n",
       "│    │    └─ReLU: 3-18                   [32, 256, 2, 8]           --\n",
       "│    │    └─Conv2d: 3-19                 [32, 256, 2, 8]           589,824\n",
       "│    │    └─BatchNorm2d: 3-20            [32, 256, 2, 8]           512\n",
       "│    │    └─Sequential: 3-21             [32, 256, 2, 8]           33,280\n",
       "│    │    └─ReLU: 3-22                   [32, 256, 2, 8]           --\n",
       "│    └─BasicBlock: 2-9                   [32, 256, 2, 8]           --\n",
       "│    │    └─Conv2d: 3-23                 [32, 256, 2, 8]           589,824\n",
       "│    │    └─BatchNorm2d: 3-24            [32, 256, 2, 8]           512\n",
       "│    │    └─ReLU: 3-25                   [32, 256, 2, 8]           --\n",
       "│    │    └─Conv2d: 3-26                 [32, 256, 2, 8]           589,824\n",
       "│    │    └─BatchNorm2d: 3-27            [32, 256, 2, 8]           512\n",
       "│    │    └─ReLU: 3-28                   [32, 256, 2, 8]           --\n",
       "├─Sequential: 1-5                        [32, 512, 1, 4]           --\n",
       "│    └─BasicBlock: 2-10                  [32, 512, 1, 4]           --\n",
       "│    │    └─Conv2d: 3-29                 [32, 512, 1, 4]           1,179,648\n",
       "│    │    └─BatchNorm2d: 3-30            [32, 512, 1, 4]           1,024\n",
       "│    │    └─ReLU: 3-31                   [32, 512, 1, 4]           --\n",
       "│    │    └─Conv2d: 3-32                 [32, 512, 1, 4]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-33            [32, 512, 1, 4]           1,024\n",
       "│    │    └─Sequential: 3-34             [32, 512, 1, 4]           132,096\n",
       "│    │    └─ReLU: 3-35                   [32, 512, 1, 4]           --\n",
       "│    └─BasicBlock: 2-11                  [32, 512, 1, 4]           --\n",
       "│    │    └─Conv2d: 3-36                 [32, 512, 1, 4]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-37            [32, 512, 1, 4]           1,024\n",
       "│    │    └─ReLU: 3-38                   [32, 512, 1, 4]           --\n",
       "│    │    └─Conv2d: 3-39                 [32, 512, 1, 4]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-40            [32, 512, 1, 4]           1,024\n",
       "│    │    └─ReLU: 3-41                   [32, 512, 1, 4]           --\n",
       "==========================================================================================\n",
       "Total params: 11,176,512\n",
       "Trainable params: 11,176,512\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.74\n",
       "==========================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 103.81\n",
       "Params size (MB): 44.71\n",
       "Estimated Total Size (MB): 150.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end = Encoder()\n",
    "i1 = torch.rand(32, 3, 32, 128)\n",
    "summary(end, input_data=i1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f466a85-12a7-40a4-b9b9-d7d2137ca0aa",
   "metadata": {},
   "source": [
    "## Content Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cecdb978-7339-4d86-b466-91b57243b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderCT(nn.Module):\n",
    "    \"\"\"Contnet Encoder using BiLSTM\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(EncoderCT, self).__init__()\n",
    "        self.content = nn.LSTM(\n",
    "            2048, 1024, num_layers=1, bidirectional=True, batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.content.flatten_parameters()\n",
    "        content_feat, _ = self.content(x.reshape(-1, 1, 512 * 1 * 4))\n",
    "        text_feat = content_feat.reshape(-1, 4, 512)\n",
    "        return content_feat, text_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af57ab9-edd0-4965-b021-976afda5670a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "EncoderCT                                [32, 1, 2048]             --\n",
       "├─LSTM: 1-1                              [32, 1, 2048]             25,182,208\n",
       "==========================================================================================\n",
       "Total params: 25,182,208\n",
       "Trainable params: 25,182,208\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 805.83\n",
       "==========================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 0.52\n",
       "Params size (MB): 100.73\n",
       "Estimated Total Size (MB): 101.52\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_ct = EncoderCT()\n",
    "i1 = torch.rand(32, 512, 1, 4)\n",
    "summary(enc_ct, input_data=i1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87bde3-198e-443e-a7e0-cdde4cefd39c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a66dbd96-4c23-4fa7-b57a-fd1c9f502bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator based on U-Net architecture(Pix2Pix)\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def basic_blk(\n",
    "            in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True\n",
    "        ):\n",
    "            layers = []\n",
    "            layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                    bias=bias,\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.BatchNorm2d(num_features=out_channels))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "            block = nn.Sequential(*layers)\n",
    "            return block\n",
    "\n",
    "        # Expansive path\n",
    "        self.dec5_1 = basic_blk(in_channels=1024, out_channels=256)\n",
    "\n",
    "        self.unpool4 = nn.ConvTranspose2d(\n",
    "            in_channels=256,\n",
    "            out_channels=256,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.dec4_2 = basic_blk(in_channels=512, out_channels=256)\n",
    "        self.dec4_1 = basic_blk(in_channels=256, out_channels=128)\n",
    "\n",
    "        self.unpool3 = nn.ConvTranspose2d(\n",
    "            in_channels=128,\n",
    "            out_channels=128,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.dec3_2 = basic_blk(in_channels=256, out_channels=128)\n",
    "        self.dec3_1 = basic_blk(in_channels=128, out_channels=64)\n",
    "\n",
    "        self.unpool2 = nn.ConvTranspose2d(\n",
    "            in_channels=64,\n",
    "            out_channels=64,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.dec2_2 = basic_blk(in_channels=128, out_channels=64)\n",
    "        self.dec2_1 = basic_blk(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.unpool1 = nn.ConvTranspose2d(\n",
    "            in_channels=64,\n",
    "            out_channels=64,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.dec1_2 = basic_blk(in_channels=128, out_channels=64)\n",
    "        self.dec1_1 = basic_blk(in_channels=64, out_channels=32)\n",
    "\n",
    "        self.unpool0 = nn.ConvTranspose2d(\n",
    "            in_channels=32,\n",
    "            out_channels=32,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.final = nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=3,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, a, b, fs):\n",
    "        f1, f2, f3, f4 = fs\n",
    "        x = torch.cat((a, b.reshape(-1, 512, 1, 4)), 1)  # x out (1024, 1, 4)\n",
    "        dec5_1 = self.dec5_1(x)  # dec5_1 out (256, 1, 4)\n",
    "\n",
    "        unpool4 = self.unpool4(dec5_1)  # unpool4 out (256, 2, 8)\n",
    "        cat4 = torch.cat((unpool4, f4), dim=1)  # cat4 out (512, 2, 8)\n",
    "        dec4_2 = self.dec4_2(cat4)  # 512 -> 256\n",
    "        dec4_1 = self.dec4_1(dec4_2)  # 256 -> 128\n",
    "\n",
    "        unpool3 = self.unpool3(dec4_1)  # unpool3 out (128, 4, 16)\n",
    "        cat3 = torch.cat((unpool3, f3), dim=1)  # cat3 out (256, 4, 16)\n",
    "        dec3_2 = self.dec3_2(cat3)  # 256 -> 128\n",
    "        dec3_1 = self.dec3_1(dec3_2)  # 128 -> 64\n",
    "\n",
    "        unpool2 = self.unpool2(dec3_1)  # unpool2 out (64, 8, 32)\n",
    "        cat2 = torch.cat((unpool2, f2), dim=1)  # cat2 out (128, 8, 32)\n",
    "        dec2_2 = self.dec2_2(cat2)  # 128 -> 64\n",
    "        dec2_1 = self.dec2_1(dec2_2)  # 64 -> 64\n",
    "\n",
    "        unpool1 = self.unpool1(dec2_1)  # unpool1 out (64, 16, 64)\n",
    "        cat1 = torch.cat((unpool1, f1), dim=1)  # cat1 out (128, 16, 64)\n",
    "        dec1_2 = self.dec1_2(cat1)\n",
    "        dec1_1 = self.dec1_1(dec1_2)\n",
    "\n",
    "        unpool0 = self.unpool0(dec1_1)  # unpool0 out (16, 64)\n",
    "        output = self.final(unpool0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ba866e7-07f7-434a-990d-14b74a456c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Generator                                [32, 3, 32, 128]          --\n",
       "├─Sequential: 1-1                        [32, 256, 1, 4]           --\n",
       "│    └─Conv2d: 2-1                       [32, 256, 1, 4]           2,359,552\n",
       "│    └─BatchNorm2d: 2-2                  [32, 256, 1, 4]           512\n",
       "│    └─ReLU: 2-3                         [32, 256, 1, 4]           --\n",
       "├─ConvTranspose2d: 1-2                   [32, 256, 2, 8]           262,400\n",
       "├─Sequential: 1-3                        [32, 256, 2, 8]           --\n",
       "│    └─Conv2d: 2-4                       [32, 256, 2, 8]           1,179,904\n",
       "│    └─BatchNorm2d: 2-5                  [32, 256, 2, 8]           512\n",
       "│    └─ReLU: 2-6                         [32, 256, 2, 8]           --\n",
       "├─Sequential: 1-4                        [32, 128, 2, 8]           --\n",
       "│    └─Conv2d: 2-7                       [32, 128, 2, 8]           295,040\n",
       "│    └─BatchNorm2d: 2-8                  [32, 128, 2, 8]           256\n",
       "│    └─ReLU: 2-9                         [32, 128, 2, 8]           --\n",
       "├─ConvTranspose2d: 1-5                   [32, 128, 4, 16]          65,664\n",
       "├─Sequential: 1-6                        [32, 128, 4, 16]          --\n",
       "│    └─Conv2d: 2-10                      [32, 128, 4, 16]          295,040\n",
       "│    └─BatchNorm2d: 2-11                 [32, 128, 4, 16]          256\n",
       "│    └─ReLU: 2-12                        [32, 128, 4, 16]          --\n",
       "├─Sequential: 1-7                        [32, 64, 4, 16]           --\n",
       "│    └─Conv2d: 2-13                      [32, 64, 4, 16]           73,792\n",
       "│    └─BatchNorm2d: 2-14                 [32, 64, 4, 16]           128\n",
       "│    └─ReLU: 2-15                        [32, 64, 4, 16]           --\n",
       "├─ConvTranspose2d: 1-8                   [32, 64, 8, 32]           16,448\n",
       "├─Sequential: 1-9                        [32, 64, 8, 32]           --\n",
       "│    └─Conv2d: 2-16                      [32, 64, 8, 32]           73,792\n",
       "│    └─BatchNorm2d: 2-17                 [32, 64, 8, 32]           128\n",
       "│    └─ReLU: 2-18                        [32, 64, 8, 32]           --\n",
       "├─Sequential: 1-10                       [32, 64, 8, 32]           --\n",
       "│    └─Conv2d: 2-19                      [32, 64, 8, 32]           36,928\n",
       "│    └─BatchNorm2d: 2-20                 [32, 64, 8, 32]           128\n",
       "│    └─ReLU: 2-21                        [32, 64, 8, 32]           --\n",
       "├─ConvTranspose2d: 1-11                  [32, 64, 16, 64]          16,448\n",
       "├─Sequential: 1-12                       [32, 64, 16, 64]          --\n",
       "│    └─Conv2d: 2-22                      [32, 64, 16, 64]          73,792\n",
       "│    └─BatchNorm2d: 2-23                 [32, 64, 16, 64]          128\n",
       "│    └─ReLU: 2-24                        [32, 64, 16, 64]          --\n",
       "├─Sequential: 1-13                       [32, 32, 16, 64]          --\n",
       "│    └─Conv2d: 2-25                      [32, 32, 16, 64]          18,464\n",
       "│    └─BatchNorm2d: 2-26                 [32, 32, 16, 64]          64\n",
       "│    └─ReLU: 2-27                        [32, 32, 16, 64]          --\n",
       "├─ConvTranspose2d: 1-14                  [32, 32, 32, 128]         4,128\n",
       "├─Conv2d: 1-15                           [32, 3, 32, 128]          99\n",
       "==========================================================================================\n",
       "Total params: 4,773,603\n",
       "Trainable params: 4,773,603\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 7.24\n",
       "==========================================================================================\n",
       "Input size (MB): 12.58\n",
       "Forward/backward pass size (MB): 137.89\n",
       "Params size (MB): 19.09\n",
       "Estimated Total Size (MB): 169.57\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = Generator()\n",
    "\n",
    "i1 = torch.rand(32, 512, 1, 4)\n",
    "i2 = torch.rand(32, 1, 1, 2048)\n",
    "i3_1 = torch.rand(32, 64, 16, 64)\n",
    "i3_2 = torch.rand(32, 64, 8, 32)\n",
    "i3_3 = torch.rand(32, 128, 4, 16)\n",
    "i3_4 = torch.rand(32, 256, 2, 8)\n",
    "i3 = [i3_1, i3_2, i3_3, i3_4]\n",
    "summary(gen, input_data=[i1, i2, i3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0450c5fc-b02f-4ef7-9f7e-ea3280402c59",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e29ca254-506d-4f37-b6ad-870eedff09ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, normalize=True):\n",
    "        super(DisBlock, self).__init__()\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, 3, stride=2, padding=1)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_channels))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef98b83c-0539-44aa-8dd9-cc8665dd15c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator based on a discriminator of PatchGAN\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.block1 = DisBlock(in_channels * 2 + 1, 64, normalize=False)\n",
    "        self.block2 = DisBlock(64, 128)\n",
    "        self.block3 = DisBlock(128, 256)\n",
    "        self.block4 = DisBlock(256, 512)\n",
    "        self.embed = nn.Sequential(*[nn.Linear(512 * 1 * 4, 32 * 128), nn.ReLU()])\n",
    "        self.patch = nn.Conv2d(512, 1, 3, padding=1)\n",
    "\n",
    "    def forward(self, a, b, c):\n",
    "        # batch, channel, height(row), width(col)\n",
    "        c_re = self.embed(c).reshape(-1, 1, 32, 128)\n",
    "        x = torch.cat((a, b, c_re), 1)\n",
    "        x1 = self.block1(x)\n",
    "        x2 = self.block2(x1)\n",
    "        x3 = self.block3(x2)\n",
    "        x4 = self.block4(x3)\n",
    "        x = self.patch(x4)\n",
    "        return x, (x1, x2, x3, x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2521cae-ec0c-4036-aeec-6bc5b2c91c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Discriminator                            [32, 1, 2, 8]             --\n",
       "├─Sequential: 1-1                        [32, 1, 4096]             --\n",
       "│    └─Linear: 2-1                       [32, 1, 4096]             8,392,704\n",
       "│    └─ReLU: 2-2                         [32, 1, 4096]             --\n",
       "├─DisBlock: 1-2                          [32, 64, 16, 64]          --\n",
       "│    └─Sequential: 2-3                   [32, 64, 16, 64]          --\n",
       "│    │    └─Conv2d: 3-1                  [32, 64, 16, 64]          4,096\n",
       "│    │    └─LeakyReLU: 3-2               [32, 64, 16, 64]          --\n",
       "├─DisBlock: 1-3                          [32, 128, 8, 32]          --\n",
       "│    └─Sequential: 2-4                   [32, 128, 8, 32]          --\n",
       "│    │    └─Conv2d: 3-3                  [32, 128, 8, 32]          73,856\n",
       "│    │    └─InstanceNorm2d: 3-4          [32, 128, 8, 32]          --\n",
       "│    │    └─LeakyReLU: 3-5               [32, 128, 8, 32]          --\n",
       "├─DisBlock: 1-4                          [32, 256, 4, 16]          --\n",
       "│    └─Sequential: 2-5                   [32, 256, 4, 16]          --\n",
       "│    │    └─Conv2d: 3-6                  [32, 256, 4, 16]          295,168\n",
       "│    │    └─InstanceNorm2d: 3-7          [32, 256, 4, 16]          --\n",
       "│    │    └─LeakyReLU: 3-8               [32, 256, 4, 16]          --\n",
       "├─DisBlock: 1-5                          [32, 512, 2, 8]           --\n",
       "│    └─Sequential: 2-6                   [32, 512, 2, 8]           --\n",
       "│    │    └─Conv2d: 3-9                  [32, 512, 2, 8]           1,180,160\n",
       "│    │    └─InstanceNorm2d: 3-10         [32, 512, 2, 8]           --\n",
       "│    │    └─LeakyReLU: 3-11              [32, 512, 2, 8]           --\n",
       "├─Conv2d: 1-6                            [32, 1, 2, 8]             4,609\n",
       "==========================================================================================\n",
       "Total params: 9,950,593\n",
       "Trainable params: 9,950,593\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.22\n",
       "==========================================================================================\n",
       "Input size (MB): 3.41\n",
       "Forward/backward pass size (MB): 32.51\n",
       "Params size (MB): 39.80\n",
       "Estimated Total Size (MB): 75.72\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc = Discriminator()\n",
    "i1 = torch.rand(32, 3, 32, 128)\n",
    "i2 = torch.rand(32, 3, 32, 128)\n",
    "i3 = torch.rand(32, 1, 2048)\n",
    "summary(disc, input_data=[i1, i2, i3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec22eb3e-320d-408e-8ce2-5ea9ec5da590",
   "metadata": {},
   "source": [
    "## Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3425c08-98e2-4296-b13b-a7d413eefe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recognizer(nn.Module):\n",
    "    \"\"\"Modified from https://github.com/clovaai/deep-text-recognition-benchmark/blob/master/modules/prediction.py\"\"\"\n",
    "\n",
    "    def __init__(self, device, input_size=512, hidden_size=256, n_class=97):\n",
    "        super(Recognizer, self).__init__()\n",
    "        self.bilstm = nn.LSTM(input_size, input_size // 2, bidirectional=True)\n",
    "        self.attention_cell = AttentionCell(input_size, hidden_size, n_class)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_class = n_class\n",
    "        self.generator = nn.Linear(hidden_size, n_class)\n",
    "        self.device = device\n",
    "\n",
    "    def _char_to_onehot(self, input_char, onehot_dim):\n",
    "        input_char = input_char.unsqueeze(1)\n",
    "        batch_size = input_char.size(0)\n",
    "        one_hot = torch.FloatTensor(batch_size, onehot_dim).zero_().to(self.device)\n",
    "        one_hot = one_hot.scatter_(1, input_char, 1)\n",
    "        return one_hot\n",
    "\n",
    "    def forward(self, feat_ct, text, is_train=True, max_len=15):\n",
    "        \"\"\"\n",
    "        input:\n",
    "            feat_ct : contextual_feature H = hidden state of encoder. [batch_size x num_steps x contextual_feature_channels]\n",
    "            text : the text-index of each image. [batch_size x (max_len+1)]. +1 for [GO] token. text[:, 0] = [GO].\n",
    "        output: probability distribution at each step [batch_size x num_steps x n_class]\n",
    "        \"\"\"\n",
    "        feat_ct, _ = self.bilstm(feat_ct)\n",
    "        batch_size = feat_ct.size(0)\n",
    "        num_steps = max_len + 1  # +1 for [s] at end of sentence.\n",
    "\n",
    "        output_hiddens = (\n",
    "            torch.FloatTensor(batch_size, num_steps, self.hidden_size)\n",
    "            .fill_(0)\n",
    "            .to(self.device)\n",
    "        )\n",
    "        hidden = (\n",
    "            torch.FloatTensor(batch_size, self.hidden_size).fill_(0).to(self.device),\n",
    "            torch.FloatTensor(batch_size, self.hidden_size).fill_(0).to(self.device),\n",
    "        )\n",
    "\n",
    "        if is_train:\n",
    "            for i in range(num_steps):\n",
    "                char_onehots = self._char_to_onehot(text[:, i], onehot_dim=self.n_class)\n",
    "\n",
    "                # hidden : decoder's hidden s_{t-1}, feat_ct : encoder's hidden H, char_onehots : one-hot(y_{t-1})\n",
    "                hidden, alpha = self.attention_cell(hidden, feat_ct, char_onehots)\n",
    "\n",
    "                # LSTM hidden index (0: hidden, 1: Cell)\n",
    "                output_hiddens[:, i, :] = hidden[0]\n",
    "            probs = self.generator(output_hiddens)\n",
    "\n",
    "        else:\n",
    "            targets = (\n",
    "                torch.LongTensor(batch_size).fill_(0).to(self.device)\n",
    "            )  # [GO] token\n",
    "            probs = (\n",
    "                torch.FloatTensor(batch_size, num_steps, self.n_class)\n",
    "                .fill_(0)\n",
    "                .to(self.device)\n",
    "            )\n",
    "\n",
    "            for i in range(num_steps):\n",
    "                char_onehots = self._char_to_onehot(targets, onehot_dim=self.n_class)\n",
    "                hidden, alpha = self.attention_cell(hidden, feat_ct, char_onehots)\n",
    "                probs_step = self.generator(hidden[0])\n",
    "                probs[:, i, :] = probs_step\n",
    "                _, next_input = probs_step.max(1)\n",
    "                targets = next_input\n",
    "\n",
    "        return probs  # batch_size x num_steps x n_class\n",
    "\n",
    "\n",
    "class AttentionCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_embeddings):\n",
    "        super(AttentionCell, self).__init__()\n",
    "        # either i2i or h2h should have bias\n",
    "        self.i2h = nn.Linear(input_size, hidden_size, bias=False)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.score = nn.Linear(hidden_size, 1, bias=False)\n",
    "        self.rnn = nn.LSTMCell(input_size + num_embeddings, hidden_size)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, prev_hidden, feat_ct, char_onehots):\n",
    "        # [batch_size x num_encoder_step x num_channel] -> [batch_size x num_encoder_step x hidden_size]\n",
    "\n",
    "        # feat_ct (N, 4, 512), feat_ct_proj (N, 4, 256)\n",
    "        feat_ct_proj = self.i2h(feat_ct)\n",
    "        prev_hidden_proj = self.h2h(prev_hidden[0]).unsqueeze(1)\n",
    "\n",
    "        # batch_size x num_encoder_step * 1\n",
    "        e = self.score(torch.tanh(feat_ct_proj + prev_hidden_proj))\n",
    "        alpha = F.softmax(e, dim=1)  # alpha (N, 4, 1)\n",
    "\n",
    "        # batch_size x num_channel\n",
    "        context = torch.bmm(alpha.permute(0, 2, 1), feat_ct).squeeze(1)\n",
    "\n",
    "        # batch_size x (num_channel + num_embedding)\n",
    "        concat_context = torch.cat([context, char_onehots], 1)\n",
    "        cur_hidden = self.rnn(concat_context, prev_hidden)\n",
    "        return cur_hidden, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c08cc169-a51c-45d8-81d4-00343be79b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Recognizer                               [32, 16, 97]              --\n",
       "├─LSTM: 1-1                              [32, 4, 512]              1,576,960\n",
       "├─AttentionCell: 1-2                     [32, 256]                 --\n",
       "│    └─Linear: 2-1                       [32, 4, 256]              131,072\n",
       "│    └─Linear: 2-2                       [32, 256]                 65,792\n",
       "│    └─Linear: 2-3                       [32, 4, 1]                256\n",
       "│    └─LSTMCell: 2-4                     [32, 256]                 887,808\n",
       "├─AttentionCell: 1-3                     [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-5                       [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-6                       [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-7                       [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-8                     [32, 256]                 (recursive)\n",
       "├─AttentionCell: 1-4                     [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-9                       [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-10                      [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-11                      [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-12                    [32, 256]                 (recursive)\n",
       "├─AttentionCell: 1-5                     [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-13                      [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-14                      [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-15                      [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-16                    [32, 256]                 (recursive)\n",
       "├─AttentionCell: 1-6                     [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-17                      [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-18                      [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-19                      [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-20                    [32, 256]                 (recursive)\n",
       "├─AttentionCell: 1-7                     [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-21                      [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-22                      [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-23                      [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-24                    [32, 256]                 (recursive)\n",
       "├─AttentionCell: 1-8                     [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-25                      [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-26                      [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-27                      [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-28                    [32, 256]                 (recursive)\n",
       "├─AttentionCell: 1-9                     [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-29                      [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-30                      [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-31                      [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-32                    [32, 256]                 (recursive)\n",
       "├─AttentionCell: 1-10                    [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-33                      [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-34                      [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-35                      [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-36                    [32, 256]                 (recursive)\n",
       "├─AttentionCell: 1-11                    [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-37                      [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-38                      [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-39                      [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-40                    [32, 256]                 (recursive)\n",
       "├─AttentionCell: 1-12                    [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-41                      [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-42                      [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-43                      [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-44                    [32, 256]                 (recursive)\n",
       "├─AttentionCell: 1-13                    [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-45                      [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-46                      [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-47                      [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-48                    [32, 256]                 (recursive)\n",
       "├─AttentionCell: 1-14                    [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-49                      [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-50                      [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-51                      [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-52                    [32, 256]                 (recursive)\n",
       "├─AttentionCell: 1-15                    [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-53                      [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-54                      [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-55                      [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-56                    [32, 256]                 (recursive)\n",
       "├─AttentionCell: 1-16                    [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-57                      [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-58                      [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-59                      [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-60                    [32, 256]                 (recursive)\n",
       "├─AttentionCell: 1-17                    [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-61                      [32, 4, 256]              (recursive)\n",
       "│    └─Linear: 2-62                      [32, 256]                 (recursive)\n",
       "│    └─Linear: 2-63                      [32, 4, 1]                (recursive)\n",
       "│    └─LSTMCell: 2-64                    [32, 256]                 (recursive)\n",
       "├─Linear: 1-18                           [32, 16, 97]              24,929\n",
       "==========================================================================================\n",
       "Total params: 2,686,817\n",
       "Trainable params: 2,686,817\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 116.67\n",
       "==========================================================================================\n",
       "Input size (MB): 0.27\n",
       "Forward/backward pass size (MB): 1.32\n",
       "Params size (MB): 10.75\n",
       "Estimated Total Size (MB): 12.33\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec = Recognizer(\"cuda\")\n",
    "i1 = torch.rand(32, 4, 512)\n",
    "i2 = torch.randint(low=2, high=96, size=(32, 16))\n",
    "summary(rec, input_data=[i1, i2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103a4da-bbb5-4402-9865-c98f0c6ecf2a",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "\n",
    "1. Generator\n",
    "2. Recognizer\n",
    "3. Perceptual\n",
    "4. Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a16f38b-a76d-422a-9a35-0335542ed00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_gen(img_gen, img_gt):\n",
    "    return F.l1_loss(img_gen, img_gt)\n",
    "\n",
    "\n",
    "def loss_synth_text(decoded, text_label):\n",
    "    decoded = decoded.view(-1, decoded.shape[-1])\n",
    "    text_label = text_label[:, 1:].contiguous().view(-1)  # ignore [GO]\n",
    "    return F.cross_entropy(decoded, text_label, ignore_index=0)\n",
    "\n",
    "\n",
    "def loss_per(img_gen_fs, img_gt_fs):\n",
    "    loss = 0.0\n",
    "    for img_gen_f, img_gt_f in zip(img_gen_fs, img_gt_fs):\n",
    "        loss += F.l1_loss(img_gen_f, img_gt_f)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def loss_adv(img_gen, img_gt):\n",
    "    return F.binary_cross_entropy_with_logits(img_gen, img_gt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
